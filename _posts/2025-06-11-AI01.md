---
title: "[TIL] 250611, MS AI 서비스를 이용한 RAG 챗봇 구현 workflow"
excerpt: "Azure AI Search와 Azure OpenAI Embedding 모델을 활용한 RAG Chatbot"

categories:
  - TIL
tags:
  - [GenAI,Azure,AI,RAG,AIAgent,python]

permalink: /TIL/250611/

toc: true
toc_sticky: true

date: 2025-06-11T13:48:02+0900
last_modified_at: 2025-06-11T13:48:02+0900
---

## Azure 포털에서 리소스 생성
1. Azure portal에서 Azure AI Search, Azure OpenAI 리소스를 생성한다.
(Azure AI Search와 Azure OpenAI 서비스를 함께 사용하려면, 해당 리소스가 **동일한 Region**에 있어야 한다.)
2. Azure OpenAI 리소스 > Azure AI Foundry 접속 > 모델 카탈로그에서 적절한 LLM, Text 임베딩모델을 생성한다. (역시 모두 동일한 Region에 있어야 함)
3. Azure Storage Account 생성 > blob storage에 임베딩할 데이터 업로드 
4. Azure AI Search 리소스 > "데이터 가져오기 및 벡터화" > Storage Account에 업로드된 데이터를 로드. (임베딩 모델은 앞서 생성한 모델을 사용)
5. Azure AI Search 리소스 > "인덱스" 에서 생성된 인덱스를 확인할 수 있다.


---

## 각 서비스별 역할 상세 설명
RAG(Retrieval Augmented Generation) 챗봇을 만들기 위해 Azure AI Search와 Azure OpenAI 서비스를 활용한다.



### 1. Azure AI Search (데이터 저장 및 검색 엔진)

Azure AI Search는 방대한 양의 데이터를 효율적으로 저장하고 검색할 수 있도록 설계된 클라우드 검색 서비스이다. RAG 챗봇의 맥락에서는 "똑똑한 도서관 사서"와 같은 역할을 수행한다.

#### 주요 역할
* **데이터 수집 및 정제**: PDF, Word 문서, 웹 페이지, 데이터베이스 기록 등 다양한 형태의 데이터를 Azure AI Search로 가져온다. 이 과정에서 불필요한 내용을 제거하거나 형식을 통일하는 등 전처리 작업이 이루어질 수 있다. 일반적으로 Azure Storage Account(Blob Storage 컨테이너)에 데이터를 업로드한 후, 이를 주기적으로 가져와 인덱싱하도록 설정한다.
* **벡터 임베딩 저장**: 원본 텍스트뿐만 아니라, 해당 텍스트의 "의미"를 숫자로 표현한 **벡터 임베딩**도 함께 저장한다. 이 벡터 임베딩은 Azure OpenAI의 임베딩 모델에 의해 생성되며, Azure AI Search는 이를 위한 저장 공간을 제공하고 관리한다. 벡터 임베딩은 텍스트 간의 의미적 유사성을 컴퓨터가 쉽게 파악할 수 있도록 돕는 역할을 한다.
* **검색 인덱스 생성**: 저장된 데이터(원본 텍스트 + 벡터 임베딩)를 효율적으로 검색하기 위해 "인덱스"를 생성한다. 인덱스는 마치 책의 찾아보기(색인)와 같아서, 특정 단어나 벡터가 어디에 있는지 빠르게 찾아낼 수 있게 해준다.
* **고속 검색 수행**: 사용자의 질문이 들어오면, Azure AI Search는 해당 질문과 의미적으로 가장 유사한 데이터(즉, 가장 가까운 벡터 임베딩을 가진 문서 조각)를 찾아 챗봇에게 반환한다. 이는 키워드 검색뿐만 아니라, 벡터 기반의 의미 검색도 포함한다.

---
### 2. Azure OpenAI Service (지능형 답변 생성기)

Azure OpenAI Service는 OpenAI의 강력한 AI 모델(GPT-3.5 Turbo, GPT-4와 같은 대규모 언어 모델 및 임베딩 모델)을 Azure 환경에서 안전하고 확장성 있게 사용할 수 있도록 제공하는 서비스이다. RAG 챗봇에서는 "똑똑한 답변 생성기" 역할을 한다.

#### 주요 역할
* **임베딩 모델 (Embedding Model)**:
    * **질문 벡터화**: 사용자가 챗봇에 질문을 입력하면, Azure OpenAI의 임베딩 모델이 이 질문의 의미를 숫자 배열인 벡터로 즉시 변환한다.
    * **데이터 벡터화 (Azure AI Search와 연동)**: RAG 챗봇 시스템 구축을 위한 데이터 준비 단계에서, 사용자의 데이터(문서 등)를 벡터화하여 Azure AI Search에 저장할 때도 이 임베딩 모델이 사용된다.
* **대규모 언어 모델 (LLM) (예: GPT-3.5 Turbo, GPT-4)**:
    * **질문 및 검색 결과 이해**: 사용자의 원본 질문 텍스트와 Azure AI Search에서 찾아온 관련성 높은 문서 조각(텍스트 형태)을 함께 입력으로 받아들인다.
    * **답변 생성**: LLM은 이 두 가지 정보를 종합하여 사용자의 질문에 대한 자연스럽고 유창하며 이해하기 쉬운 답변을 생성한다. LLM은 단순히 정보를 복사하는 것을 넘어, 정보를 요약하거나, 다른 정보와 결합하거나, 질문의 뉘앙스에 맞춰 어조를 조절하는 등 창의적인 답변 생성 능력을 가진다.

---
### RAG 챗봇의 Workflow

1.  **사용자 질문**: 사용자가 챗봇에 질문을 입력한다.
2.  **질문 벡터화 (Azure OpenAI 임베딩 모델)**: 챗봇은 이 질문을 Azure OpenAI의 임베딩 모델을 사용하여 벡터로 변환한다.
3.  **관련 문서 검색 (Azure AI Search)**: 챗봇은 벡터화된 질문을 Azure AI Search에 보내, 미리 저장해 둔 데이터(벡터 임베딩 포함) 중에서 의미적으로 가장 유사한 관련 문서 조각을 찾아오도록 요청한다. Azure AI Search는 해당 부분을 빠르게 찾아 챗봇에게 반환한다.
4.  **답변 생성 (Azure OpenAI LLM)**: 챗봇은 사용자의 원본 질문과 Azure AI Search에서 찾아온 관련 문서 내용을 함께 Azure OpenAI의 대규모 언어 모델(LLM)에 전달한다.
5.  **최종 답변 전달**: LLM은 제공받은 정보를 바탕으로 사용자의 질문에 대한 자연스럽고 정확한 답변을 생성하여 챗봇을 통해 사용자에게 전달한다.

이러한 과정을 통해 RAG 챗봇은 단순히 정해진 답변만 하는 것이 아니라, 방대한 데이터베이스에서 실시간으로 필요한 정보를 찾아내고 이를 바탕으로 유연하고 정확한 답변을 제공하는 지능적인 비서 역할을 수행한다.


