---
title: "[TIL] 250612, AI 모델의 최적화와 활용 전략"
excerpt: "Fine-tuning, SLM, Agentic-AI"

categories:
  - TIL
tags:
  - [GenAI,Azure,AI,RAG,LLM,FineTuning,AgenticAI,python]

permalink: /TIL/250612/

toc: true
toc_sticky: true

date: 2025-06-12T13:48:02+0900
last_modified_at: 2025-06-12T13:48:02+0900
---


## 💡 Today I Learned: AI 모델의 최적화와 활용 전략

AI 모델, 특히 LLM은 그 자체로 강력하지만, 특정 목적에 맞게 더욱 효율적으로 활용하고 배포하기 위한 다양한 기술들이 지속적으로 발전하고 있다.<br>
**Fine-tuning(파인튜닝)**, **SLM(Small Language Model)**, 그리고 **Agentic AI**의 개념과 활용법을 정리해보았다.



### 1. Fine-tuning (파인튜닝)

파인튜닝은 이미 방대한 데이터를 통해 일반적인 지식을 습득한 **사전 학습된(pre-trained) LLM**을 특정 작업(예: 감성 분석, 질문 답변, 특정 산업 도메인 지식 습득)이나 사용자 정의 데이터셋에 맞게 **추가로 학습**시키는 과정이다.<br>
이는 모델이 특정 분야에서 더 정확하고 관련성 높은 응답을 생성하도록 '맞춤옷'을 입히는 것과 같음<br>

* **다운스트림(Downstream) 작업에 최적화:** 파인튜닝의 주 목적은 특정 **하위 작업(downstream task)** 에서 모델의 성능을 극대화하는 것임. 이 과정에서 모델의 파라미터(가중치)를 조정하므로, **고성능 GPU**와 상당한 컴퓨팅 자원, 그리고 학습 시간이 필수적으로 요구됨.
* **정적(Static) 모델의 생성:** 파인튜닝이 완료되면, 해당 모델은 파인튜닝 시 사용된 데이터에 기반한 지식을 갖는 **정적인 상태**가 된다. 이는 모델이 학습이 완료된 특정 시점의 데이터에 고정된다는 의미
    * **제약 사항:** 새로운 정보가 지속적으로 발생하거나, 사용자 요구사항이 빠르게 변화하는 경우, 정적 모델은 최신성을 유지하기 어렵다. 이러한 경우, 모델을 **다시 파인튜닝(re-fine-tune)**해야 하는데, 이는 상당한 시간과 비용이 소요되므로 변동성이 많은 데이터로 fine tuning하는 것은 부적절함
    * **RAG와의 시너지:** 이러한 정적 모델의 한계를 보완하기 위해 **RAG(검색 증강 생성)** 기법이 각광받고 있음. RAG는 LLM이 답변을 생성하기 전에 외부 지식 저장소(데이터베이스, 문서 등)에서 관련 정보를 실시간으로 검색하여 활용하는 방식. 모델 자체를 업데이트할 필요 없이 최신 정보를 반영할 수 있어, 파인튜닝된 정적 모델의 강점(특정 도메인 이해)과 RAG의 강점(최신 정보 반영)을 결합하여 더욱 강력한 시스템을 구축할 수 있다. Prompt Engineering과 RAG는 저비용, Fine-Tuning은 고비용이므로 Fine-Tuning은 가장 최후의 수단으로 고려하는 것이 바람직함. 
* **학습 데이터 형식:** 파인튜닝에 사용되는 데이터는 일반적으로 **JSONL(`jsonl`) 형식**으로 구성. 각 줄은 하나의 대화 예시를 나타내며, `messages` 배열 안에 `role` (시스템, 사용자, AI 어시스턴트)과 `content`를 포함하는 메시지 객체들로 구성. `weight` 속성을 추가하여 특정 응답(주로 어시스턴트의 답변)에 더 높은 학습 가중치를 부여함으로써, 모델이 해당 응답 패턴을 더 중요하게 학습하도록 유도할 수 있음.
    ```json
    {"messages": [{"role": "system", "content": "Marv is a factual chatbot that is also sarcastic."}, {"role": "user", "content": "What's the capital of France?"}, {"role": "assistant", "content": "Paris", "weight": 0}, {"role": "user", "content": "Can you be more sarcastic?"}, {"role": "assistant", "content": "Paris, as if everyone doesn't know that already.", "weight": 1}]}
    ```



### 2. LLM 경량화: SLM과 On-Device AI

LLM은 뛰어난 성능을 자랑하지만, 막대한 계산량과 메모리 요구사항 때문에 모든 환경(특히 엣지 디바이스)에서 사용하기는 어렵다. <br>
이러한 제약을 극복하기 위해 LLM을 **소형 언어 모델(SLM: Small Language Model)**로 축소하는 **모델 경량화(Model Quantization/Pruning)** 기술이 중요해지고 있음.<br>
SLM은 LLM에 비해 가볍고 효율적이므로, **인프라 제약이 적은 환경**에서도 구동이 가능하며, 이는 궁극적으로 **"On-Device AI"** 시대를 가속화한다.<br>

* **양자화(Quantization):** 모델의 가중치(파라미터) 정밀도를 낮추는 기술. 예를 들어, 일반적으로 사용되는 16비트(16-bit) 또는 32비트(32-bit) 부동소수점 가중치를 8비트(8-bit) 또는 4비트(4-bit) 정수로 줄여 모델의 크기와 메모리 사용량을 획기적으로 감소시킴. 모바일 기기나 임베디드 시스템에서도 AI 모델을 실행할 수 있는 기반을 마련함.
* **가지치기(Pruning):** 모델 내에서 중요도가 낮거나 연산에 거의 기여하지 않는 신경망 연결(가중치)을 영구적으로 제거하는 기술. 모델의 희소성(sparsity)을 높여 실제 연산량을 줄이고, 결과적으로 모델의 추론 속도를 향상시킴
* **SLM의 실제 사례:**
    * **`gpt-..-mini`, `gpt-..-nano`:** OpenAI 등 주요 AI 기업들이 제공하는 SLM에 가까운 라인업
    * **`phi`:** 마이크로소프트에서 개발한 SLM. Windows 운영체제에 기본 탑재
    * **`gemma`:** 구글의 개방형 SLM 시리즈로, 특히 모바일 기기(예: 삼성 갤럭시 스마트폰)에 온디바이스 AI 형태로 탑재
* **SLM의 파인튜닝:** SLM 또한 특정 목적에 맞게 파인튜닝이 가능하며, LLM 파인튜닝보다 **훨씬 적은 자원과 시간**으로 가능. (EX. **군대 용어, 특정 기업의 사내 문서, 또는 콜센터 스크립트**와 같은 특정 도메인 데이터만으로 SLM을 파인튜닝하면, 해당 분야에서 더욱 '영리하고' 정확한 답변을 생성하는 맞춤형 AI를 구축할 수 있다. 제한된 환경에서 강력한 AI 기능을 구현할 수 있는 실용적인 방안.



### 3. Agentic AI (에이전트 AI): 자율성과 도구 활용 능력

기존의 LLM이 주어진 질문에 대한 텍스트를 생성하는 데 그쳤다면, **Agentic AI(에이전트 AI)** 는 언어 모델이 단순히 텍스트를 넘어 **목표를 이해하고, 계획을 수립하며, 외부 도구(Tools)를 자율적으로 활용하여 복잡한 작업을 수행하고 목표를 달성**하도록 설계된 AI 시스템. <br>
LLM의 추론 능력을 극대화하여 실제 문제 해결 능력을 부여한다.<br>

* **도구 활용의 핵심:** 에이전트 AI는 **웹 검색 도구(Web Search Tool)**, **데이터베이스(Database) 접근 도구**, **파일 시스템(File System) 조작 도구**, **API 호출 도구** 등 다양한 외부 도구들과 연동함. LLM은 자신의 지식만으로는 부족할 때, 어떤 도구를 언제 어떻게 사용할지 스스로 판단하고 실행함
* **자율성과 오케스트레이션(Orchestration):** 에이전트 AI는 단순한 질문-답변을 넘어, 여러 단계를 거쳐 목표를 달성하는 **자율적인 워크플로우**를 가진다. 이때 여러 에이전트나 도구들의 상호작용을 효율적으로 조정하고 관리하는 **오케스트레이션** 기술이 중요. 여러 전문가가 모여 프로젝트를 수행하는 것과 유사한 형태
* **주요 프레임워크:**
    * **LangChain & LangGraph:** 언어 모델 기반 애플리케이션 개발을 위한 대표적인 오픈소스 프레임워크. LLM과 외부 시스템을 연결하고, 복잡한 체인(Chain)이나 그래프(Graph) 형태로 워크플로우를 구성하여 에이전트를 구축하는 데 강력. (LangGraph가 Agentic AI 구현에 적절)
    * **CrewAI:** 다수의 AI 에이전트가 각자의 역할(Role)과 목표(Goal)를 가지고 협력하여 복잡한 프로젝트를 수행하도록 설계된 오케스트레이션 프레임워크.
    * **AutoGen (Microsoft):** 마이크로소프트에서 개발한 오픈소스 프레임워크로, 대규모 언어 모델을 기반으로 한 자율적이고 대화형 에이전트 개발을 지원.
    * 등등


